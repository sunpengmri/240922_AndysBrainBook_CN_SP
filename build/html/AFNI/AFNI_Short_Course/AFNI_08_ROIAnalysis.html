<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AFNI Tutorial #8: ROI Analysis &mdash; Andy&#39;s Brain Book 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b76e3c8a" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="AFNI Tutorial #9: Surface-Based Analysis with SUMA" href="AFNI_09_SurfaceAnalysis.html" />
    <link rel="prev" title="AFNI Tutorial #7: Group Analysis" href="AFNI_07_GroupAnalysis.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Andy's Brain Book
          </a>
              <div class="version">
                1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Install</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation/fsl_mac_install.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Unix for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_Intro.html">What is Unix?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_01_Navigation.html">Unix Tutorial #1: 目录操作 (Directories and Navigation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_02_CopyRemove.html">Unix Tutorial #2: Copying and Removing Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_03_ReadingTextFiles.html">Unix Tutorial #3: Reading Text Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_04_ShellsVariables.html">Unix Tutorial #4: Shells and Path Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_05_ForLoops.html">Unix Tutorial #5: For-Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_06_IfElse.html">Unix Tutorial #6: Conditional Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_07_Scripting.html">Unix Tutorial #7: Scripting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_08_Sed.html">Unix Tutorial #8: The Sed Command</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_09_AutomatingTheAnalysis.html">Unix Tutorial #9: Automating The Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">fMRI Short Course with FSL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_Intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_01_DataDownload.html">fMRI Tutorial #1: Downloading the Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_02_ExperimentalDesign.html">fMRI Tutorial #2: Overview of The Flanker Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_03_LookingAtTheData.html">fMRI Tutorial #3: Looking at the Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_04_Preprocessing.html">fMRI Tutorial #4: Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_05_1stLevelAnalysis.html">fMRI Tutorial #5: Statistics and Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_06_Scripting.html">fMRI Tutorial #6: Scripting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_07_2ndLevelAnalysis.html">fMRI Tutorial #7: 2nd-Level Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_08_3rdLevelAnalysis.html">fMRI Tutorial #8: 3rd-Level Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_09_ROIAnalysis.html">fMRI Tutorial #9: ROI Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_10_Summary.html">fMRI Tutorial #10: Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_Appendices.html">fMRI Short Course: Appendices</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FreeSurfer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../FreeSurfer/FreeSurfer_Introduction.html">FreeSurfer Short Course</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">E-Prime</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../E-Prime/E-Prime_Overview.html">Overview of E-Prime</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AFNI</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../AFNI_Overview.html">AFNI Overview</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../AFNI_Overview.html#what-is-afni">What is AFNI?</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="AFNI_fMRI_Intro.html">Introduction to AFNI</a></li>
<li class="toctree-l3"><a class="reference internal" href="AFNI_01_DataDownload.html">AFNI Tutorial #1: Downloading the Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="AFNI_02_ExperimentalDesign.html">AFNI Tutorial #2: The Flanker Experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="AFNI_03_LookingAtTheData.html">AFNI Tutorial #3: Looking at the Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="AFNI_04_Preprocessing.html">AFNI Tutorial #4: AFNI Commands and Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="AFNI_05_1stLevelAnalysis.html">AFNI Tutorial #5: Statistics and Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="AFNI_06_Scripting.html">AFNI Tutorial #6: Scripting</a></li>
<li class="toctree-l3"><a class="reference internal" href="AFNI_07_GroupAnalysis.html">AFNI Tutorial #7: Group Analysis</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">AFNI Tutorial #8: ROI Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-atlases">Using Atlases</a></li>
<li class="toctree-l4"><a class="reference internal" href="#extracting-data-from-the-anatomical-mask">Extracting Data from the Anatomical Mask</a></li>
<li class="toctree-l4"><a class="reference internal" href="#extracting-data-from-an-sphere">Extracting Data from an Sphere</a></li>
<li class="toctree-l4"><a class="reference internal" href="#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="#video">Video</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="AFNI_09_SurfaceAnalysis.html">AFNI Tutorial #9: Surface-Based Analysis with SUMA</a></li>
<li class="toctree-l3"><a class="reference internal" href="AppendixA_ParametricModulation.html">Appendix A: Parametric Modulation in AFNI</a></li>
<li class="toctree-l3"><a class="reference internal" href="AppendixB_AnimalAnalysis.html">Appendix B: Analyzing Rat Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="AppendixC_HighlightingResults.html">Appendix C: Highlighting Vs. Hiding Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="AppendixD_EffectSizes.html">Appendix D: Reporting Effect Sizes</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SPM</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../SPM/SPM_Overview.html">SPM Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Functional Connectivity with the CONN Toolbox</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionalConnectivity/CONN_Overview.html">Functional Connectivity and the CONN Toolbox</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parametric Modulation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PM/PM_Overview.html">Parametric Modulation in SPM, FSL, and AFNI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image Visualization with MRIcroGL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../MRIcroGL/MRIcroGL_Overview.html">Image Visualization with MRIcroGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to the Human Connectome Project (HCP)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../HCP/HCP_Overview.html">Introduction to the Human Connectome Project</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Finite Impulse Response (FIR) Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../FIR/FIR_Overview.html">Finite Impulse Response (FIR)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">fMRI Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Practicals/DesignOptimization.html">Design Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Diffusion Analysis with MRtrix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../MRtrix/MRtrix_Introduction.html">Introduction to MRtrix</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ASL Analysis</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/ASL_Techniques.html">fASL Tutorial #1: Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/fASL_02_Download.html">fASL Tutorial #2: Downloading and Installing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/fASL_03_Task.html">fASL Tutorial #3: The N-Back Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/04_fASL_GUI.html">fASL Tutorial #4: The GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/05_fASL_Results.html">fASL Tutorial #5: Examining the Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/06_fASL_Quantification.html">fASL Tutorial #6: Quantification</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frequently Asked Questions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../FrequentlyAskedQuestions/FrequentlyAskedQuestions.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Statistics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Statistics/GIMME.html">GIMME (Group Iterative Multiple Model Estimation)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Open Science</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../OpenScience/OS_Overview.html">Open Science</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Normalization Tools (ANTs)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ANTs/ANTs_Overview.html">Advanced Normalization Tools (ANTs)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tract-Based Spatial Statistics (TBSS)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../TBSS/TBSS_Overview.html">Introduction to Tract-Based Spatial Statistics (TBSS)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Statistics for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Stats/Stats_Overview.html">Statistics for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Machine Learning for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ML/ML_Overview.html">Machine Learning for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Slicer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Slicer/Slicer_Overview.html">Slicer Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CAT12</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../CAT12/CAT12_Overview.html">Voxel-Based Morphometry with CAT12</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Using the Supercomputer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Supercomputer/Supercomputer_Overview.html">Introduction to Supercomputing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Matlab for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Matlab/Matlab_Overview.html">Matlab for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ITK-Snap</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ITK-Snap/ITK-Snap_Overview.html">ITK-Snap_Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PythonForNeuroimagers/PythonForNeuroimagers_Overview.html">Python for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Meta-Analysis for fMRI</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../MetaAnalysis/MetaAnalysis_Overview.html">Meta-Analysis for Neuroimagers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Andy's Brain Book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../AFNI_Overview.html">AFNI Overview</a></li>
      <li class="breadcrumb-item active">AFNI Tutorial #8: ROI Analysis</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/AFNI/AFNI_Short_Course/AFNI_08_ROIAnalysis.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="afni-tutorial-8-roi-analysis">
<span id="afni-08-roianalysis"></span><h1>AFNI Tutorial #8: ROI Analysis<a class="headerlink" href="#afni-tutorial-8-roi-analysis" title="Link to this heading"></a></h1>
<hr class="docutils" />
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>You’ve just completed a group-level analysis, and identified which regions of the brain show a significant difference between the Incongruent and Congruent conditions of the experiment. For some researchers, this may be all that they want to do.</p>
<p>This kind of analysis is called a <strong>whole-brain</strong> or <strong>exploratory</strong> analysis. These types of analyses are useful when the experimenter doesn’t have a hypothesis about where the difference may be located; the result will be used as the basis for future research.</p>
<p>When a large number of studies have been run about a specific topic, however, we can begin to make more specific hypotheses about where we should find our results in the brain images. For example, cognitive control has been studied for many years, and many fMRI studies have been published about it using different paradigms that compare more cognitively demanding tasks to less cognitively demanding tasks. Often, significant increases in the BOLD signal during cognitively demanding conditions are seen in a region of the brain known as the <strong>dorsal medial prefrontal cortex</strong>, or dmPFC for short. For the Flanker study, then, we could restrict our analysis to this region and only extract data from voxels within that region. This is known as a <strong>region of interest (ROI)</strong> analysis. A general name for an analysis in which you choose to analyze a region selected before you look at whole-brain results is called a <strong>confirmatory analysis</strong>.</p>
<p>Whole-brain maps can hide important details about the effects that we’re studying. We may find a significant effect of incongruent-congruent, but the reason the effect is significant could be because incongruent is greater than congruent, or because congruent is much more negative than congruent, or some combination of the two. The only way to determine what is driving the effect is with ROI analysis, and this is especially important when dealing with interactions and more sophisticated designs.</p>
</section>
<section id="using-atlases">
<h2>Using Atlases<a class="headerlink" href="#using-atlases" title="Link to this heading"></a></h2>
<p>One way to create a region for our ROI analysis is to use an <strong>atlas</strong>, or a map that partitions the brain into anatomically distinct regions.</p>
<p>AFNI comes with several atlases in both Talairach and MNI space, which can be accessed through the AFNI GUI. Finding the atlases can be difficult - you must first click on <code class="docutils literal notranslate"><span class="pre">Define</span> <span class="pre">Datamode</span></code>, and then click on <code class="docutils literal notranslate"><span class="pre">Plugins</span></code>, and from the dropdown menu select <code class="docutils literal notranslate"><span class="pre">Draw</span> <span class="pre">Dataset</span></code>. The figure below shows the Draw Dataset window.</p>
<figure class="align-default" id="id3">
<img alt="../../_images/08_DrawDataSetWindow.png" src="../../_images/08_DrawDataSetWindow.png" />
<figcaption>
<p><span class="caption-text">After opening up the AFNI GUI, click on the buttons in the order shown in the figure (1, 2, and 3).</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Once you have opened the Draw Dataset window, you will first need to click on the button <code class="docutils literal notranslate"><span class="pre">Choose</span> <span class="pre">dataset</span> <span class="pre">for</span> <span class="pre">copying</span></code>. Since all of our data has been normalized to the MNI_avg152T1 template, we have two options:</p>
<ol class="arabic simple">
<li><p>Select the MNI_avg152T1+tlrc template from the <code class="docutils literal notranslate"><span class="pre">abin</span></code> directory; or</p></li>
<li><p>Select one of the normalized anatomical images from the Flanker dataset.</p></li>
</ol>
<p>In both cases, the images will be in MNI space and will have the same dimensions and voxel resolution. The purpose of making a copy of that dataset is to create a “clean” dataset with the same dimensions as the other images, but which we can write on by marking whichever voxels we want to belong to our ROI. In this case, navigate to the <code class="docutils literal notranslate"><span class="pre">sub-01/sub-01.results</span></code> directory, open the AFNI GUI, and open the Draw Dataset window. For the image to copy, select the file <code class="docutils literal notranslate"><span class="pre">anat_file.sub-01</span></code>.</p>
<p>Once you have done that, you have several different atlases to select from. For the current tutorial, select the atlas <code class="docutils literal notranslate"><span class="pre">DD_Desai_MPM</span></code>, and then click on the dropdown menu below it. You have many different regions to choose from, and the voxels represented by each label can be guessed at by the name; for example, <code class="docutils literal notranslate"><span class="pre">ctx_lh_G_and_S_frontomargin</span></code> probably refers to the cortical voxels of the gyrus and sulcus of the frontomarginal region of the left hemisphere.</p>
<p>Select <code class="docutils literal notranslate"><span class="pre">ctx_lh_G_and_S_cingul_-Mid_Ant</span></code>, and then click on the button <code class="docutils literal notranslate"><span class="pre">Load:</span> <span class="pre">InFill</span></code>. This will highlight in red all of the voxels belonging to that region of the atlas. You can undo this by clicking on the <code class="docutils literal notranslate"><span class="pre">Undo</span></code> button, which keeps several steps in memory. Now right-click the area to the left of the label dropdown menu to open a more compact view of the atlas regions, and select <code class="docutils literal notranslate"><span class="pre">ctx_rh_G_and_S_cingul-Mid-Ant</span></code>. Click on <code class="docutils literal notranslate"><span class="pre">Load:</span> <span class="pre">InFill</span></code> to add that region to the current mask, and then click <code class="docutils literal notranslate"><span class="pre">SaveAs</span></code>. Call the output <code class="docutils literal notranslate"><span class="pre">midACC</span></code>. This will create a new file that contains values of “1” in the voxels that belong to the region, and zeros everywhere else; this is also known as a <strong>mask</strong>. When you are finished, click <code class="docutils literal notranslate"><span class="pre">Done</span></code>.</p>
<figure class="align-default" id="id4">
<img alt="../../_images/08_AtlasMask.png" src="../../_images/08_AtlasMask.png" />
<figcaption>
<p><span class="caption-text">You can choose an atlas from the dropdown menu (1), and then choose a corresponding label from the atlas (2). Clicking on Load: InFill (3) will highlight those voxels within that label, and you can save the mask by clicking on SaveAs (4).</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The default in AFNI is for the results dataset to have a different resolution than both the normalized anatomical image and the template used for normalization. The AFNI template we used was the MNI_avg152T1+tlrc file, which has a resolution of 2x2x2mm; our statistics dataset, on the other hand, has a resolution of 3x3x3mm. In order to use a mask for an ROI analysis, it needs to be the same resolution as the dataset you are extracting from.</p>
</div>
<p>We can match the resolutions of our mask dataset and our statistics dataset by using AFNI’s <code class="docutils literal notranslate"><span class="pre">3dresample</span></code> command. This command requires both a “master” dataset, which we will be resampling to, and an “input” dataset, which will have its dimensions and resolution changed to match the master datset:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dresample</span> <span class="o">-</span><span class="n">master</span> <span class="n">stats</span><span class="o">.</span><span class="n">sub</span><span class="o">-</span><span class="mi">01</span><span class="o">+</span><span class="n">tlrc</span> <span class="o">-</span><span class="nb">input</span> <span class="n">midACC</span><span class="o">+</span><span class="n">tlrc</span> <span class="o">-</span><span class="n">prefix</span> <span class="n">midACC_rs</span><span class="o">+</span><span class="n">tlrc</span>
</pre></div>
</div>
<p>This will create a new file, midACC_rs (in which <strong>rs</strong> stands for re-sampled). Move this mask to the subject directory by typing <code class="docutils literal notranslate"><span class="pre">mv</span> <span class="pre">midACC_rs+tlrc*</span> <span class="pre">../..</span></code>. We can then use it to extract data for our ROI analysis.</p>
</section>
<section id="extracting-data-from-the-anatomical-mask">
<h2>Extracting Data from the Anatomical Mask<a class="headerlink" href="#extracting-data-from-the-anatomical-mask" title="Link to this heading"></a></h2>
<p>Once you’ve created the mask, you can then extract each subject’s contrast estimates from it. There are two ways that we could extract our contrast of interest Incongruent-Congurent:</p>
<ol class="arabic simple">
<li><p>Extract the contrast estimate Incongruent-Congruent from our stats file; or</p></li>
<li><p>Extract the individual beta weights for Incongruent and Congruent separately, and then take the difference between the two.</p></li>
</ol>
<p>As we will see, option #2 allows you to determine what is driving the effect; in other words, whether a significant effect is due to both beta weights being positive but the Incongruent beta weights being more positive, both weights being negative but the Congruent betas more negative, or a combination of the two. It is only by extracting both sets of beta weights that we can determine this.</p>
<p>First, from the subjects directory type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dinfo</span> <span class="o">-</span><span class="n">verb</span> <span class="n">sub</span><span class="o">-</span><span class="mi">01</span><span class="o">/</span><span class="n">sub</span><span class="o">-</span><span class="mf">01.</span><span class="n">results</span><span class="o">/</span><span class="n">stats</span><span class="o">.</span><span class="n">sub</span><span class="o">-</span><span class="mi">01</span><span class="o">+</span><span class="n">tlrc</span><span class="o">.</span>
</pre></div>
</div>
<p>This will return a list of all the beta weights and contrast weights contained in the stats file.</p>
<figure class="align-default">
<img alt="../../_images/08_stats_weights.png" src="../../_images/08_stats_weights.png" />
</figure>
<p>The sub-briks index which beta weight belongs to which volume in the dataset. In this example, the beta weight for the Congruent condition is sub-brik 1, the beta weight for the Incongruent condition is sub-brik 4, and the contrast weight for Incongruent-Congruent is sub-brik 7. For this tutorial, we will extract sub-briks 1 and 4 and store them in separate files, and then extract the values for each subject from an ROI.</p>
<p>The individual sub-briks can be extracted using the following code, <a class="reference external" href="https://github.com/andrewjahn/AFNI_Scripts/blob/master/extractBetas.sh">extractBetas.sh</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash

for subj in `cat subjList.txt`; do

        3dbucket -aglueto Congruent_betas+tlrc.HEAD ${subj}/${subj}.results/stats.${subj}+tlrc&#39;[1]&#39;
        3dbucket -aglueto Incongruent_betas+tlrc.HEAD ${subj}/${subj}.results/stats.${subj}+tlrc&#39;[4]&#39;

done
</pre></div>
</div>
<p>When it finishes, you will have generated two new datasets: Congruent_betas and Incongruent_betas. Open up one of the datasets in your viewer, and click on the <code class="docutils literal notranslate"><span class="pre">Graph</span></code> button of the AFNI GUI to scroll through the different volumes. How is this “time-series” different from the time-series you viewed in the raw imaging data? As another exercise, from the command line type <code class="docutils literal notranslate"><span class="pre">3dinfo</span> <span class="pre">-nt</span> <span class="pre">Congruent_betas+tlrc</span></code>, in which the “-nt” option returns the number of volumes (or time-points) in the dataset. What number is returned, and what does it represent? Does it make sense?</p>
<p>You can now extract data from the anatomical mask by using the <code class="docutils literal notranslate"><span class="pre">3dmaskave</span></code> command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dmaskave</span> <span class="o">-</span><span class="n">quiet</span> <span class="o">-</span><span class="n">mask</span> <span class="n">midACC_rs</span><span class="o">+</span><span class="n">tlrc</span> <span class="n">Congruent_betas</span><span class="o">+</span><span class="n">tlrc</span>
</pre></div>
</div>
<p>Run the same command for the incongruent betas as well:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dmaskave</span> <span class="o">-</span><span class="n">quiet</span> <span class="o">-</span><span class="n">mask</span> <span class="n">midACC_rs</span><span class="o">+</span><span class="n">tlrc</span> <span class="n">Incongruent_betas</span><span class="o">+</span><span class="n">tlrc</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Each number output from this command corresponds to the contrast estimate that went into the analysis. For example, the first number corresponds to the average contrast estimate for Incongruent-Congruent for sub-01, the second number is the average contrast estimate for sub-02, and so on. These numbers can be copied and pasted into a statistical software package of your choice (such as R), and then you can run a t-test on them.</p>
</div>
</section>
<section id="extracting-data-from-an-sphere">
<h2>Extracting Data from an Sphere<a class="headerlink" href="#extracting-data-from-an-sphere" title="Link to this heading"></a></h2>
<p>You may have noticed that the results from the ROI analysis using the anatomical mask were not significant. This may be because the ACC mask covers a very large region; although the ACC is labeled as a single anatomical region, we may be extracting data from several distinct functional regions. Consequently, this may not be the best ROI approach to take.</p>
<p>Another technique is called the <strong>spherical ROI</strong> approach. In this case, a sphere of a given diameter is centered at a triplet of specified x-, y-, and z-coordinates. These coordinates are often based on the peak activation of another study that uses the same or a similar experimental design to what you are using. This is considered an <strong>independent</strong> analysis, since the ROI is defined based on a separate study.</p>
<p>The following animation shows the difference between anatomical and spherical ROIs:</p>
<figure class="align-default">
<img alt="../../_images/08_ROI_Analysis_Anatomical_Spherical.gif" src="../../_images/08_ROI_Analysis_Anatomical_Spherical.gif" />
</figure>
<p>To create this ROI, we will need to find peak coordinates from another study; let’s randomly pick a paper, such as Jahn et al., 2016. In the Results section, we find that there is a Conflict effect for a Stroop task - a distinct but related experimental design also intended to tap into cognitive control - with a peak t-statistic at MNI coordinates 0, 20, 40.</p>
<figure class="align-default">
<img alt="../../_images/08_ROI_Analysis_Jahn_Study.png" src="../../_images/08_ROI_Analysis_Jahn_Study.png" />
</figure>
<p>We will create a <strong>spherical mask</strong> centered at these coordinates by using the command <code class="docutils literal notranslate"><span class="pre">3dUndump</span></code>. The following code will place a 5mm sphere around the coordinates 0, 20, 44:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="c1"># This script creates a 5mm sphere around a coordinate</span>
<span class="c1"># Change the x,y,z, coordinates on the left side to select a different peak</span>
<span class="c1"># Radius size can be changed with the -srad option</span>

<span class="n">echo</span> <span class="s2">&quot;0 20 44&quot;</span> <span class="o">|</span> <span class="mi">3</span><span class="n">dUndump</span> <span class="o">-</span><span class="n">orient</span> <span class="n">LPI</span> <span class="o">-</span><span class="n">srad</span> <span class="mi">5</span> <span class="o">-</span><span class="n">master</span> <span class="n">Incongruent_betas</span><span class="o">+</span><span class="n">tlrc</span> <span class="o">-</span><span class="n">prefix</span> <span class="n">ConflictROI</span><span class="o">+</span><span class="n">tlrc</span> <span class="o">-</span><span class="n">xyz</span> <span class="o">-</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">-srad</span></code> option specifies how large the radius of the sphere will be, while the <code class="docutils literal notranslate"><span class="pre">-master</span></code> option creates a mask dataset with the same resolution and voxel size as the master dataset. (Note that this means we won’t have to resample the ROI created with this command.) The <code class="docutils literal notranslate"><span class="pre">-prefix</span></code> option labels the output file, and <code class="docutils literal notranslate"><span class="pre">-xyz</span></code> specifies the coordinates around which to center the sphere. the <code class="docutils literal notranslate"><span class="pre">-</span></code> after the -xyz option indicates that the output on the left side of the pipe - i.e., <a href="#id1"><span class="problematic" id="id2">``</span></a>echo “0 20 44” - should be used as the input for that option.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The coordinates reported in most papers are in <code class="docutils literal notranslate"><span class="pre">LPI</span></code> orientation - that is, the coordinates increase in magnitude from negative to positive going from Left to Right, Posterior to Anterior, and Inferior to Superior. The letters in LPI correspond to the first letter in each of these pairings. The default orientation for AFNI datasets, on the other hand, is <code class="docutils literal notranslate"><span class="pre">RAI</span></code> - negative to positive going from Right to Left, Anterior to Posterior, and Inferior to Superior. For example, the coordinates 10, -14, 38 in LPI orientation would be -10, 14, 38 in RAI orientation. We use the -orient LPI option to convert the AFNI RAI coordinates to LPI coordinates.</p>
</div>
<p>The result of this command will be a file called <code class="docutils literal notranslate"><span class="pre">ConflictROI</span></code>, which you can then use for an ROI analysis. We will use the same 3dmaskave command as above:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dmaskave</span> <span class="o">-</span><span class="n">quiet</span> <span class="o">-</span><span class="n">mask</span> <span class="n">ConflictROI</span><span class="o">+</span><span class="n">tlrc</span> <span class="n">Congruent_betas</span><span class="o">+</span><span class="n">tlrc</span>
</pre></div>
</div>
<p>The output will be 26 rows, one number per row, representing the average beta estimate across the voxels of the mask that we extracted from. Use the same command to extract the beta estimates for the Incongruent_betas file, and then copy and paste both sets of numbers into a statistical software package.</p>
<p>The numbers you get from this analysis should look much different from the ones you created using the anatomical mask. Copy and paste these commands into the statistical software package of your choice, and run a one-sample t-test on them. Are they significant? How would you describe them if you had to write up these results in a manuscript?</p>
</section>
<hr class="docutils" />
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Create an anatomical mask of a region of your choosing. For the copy dataset, select the “stats” dataset. Will you have to resample this mask in order to use it for an ROI analysis? Why or why not?</p></li>
<li><p>Use the code given in the section on spherical ROI analysis to create a sphere with a 7mm radius located at MNI coordinates 36, -2, 48.</p></li>
<li><p>Run an ROI analysis with the original spherical ROI that we created in the tutorial above, using the beta weights from the REML dataset. How different are the results? Which statistical dataset would you prefer to use, and why?</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="video">
<h2>Video<a class="headerlink" href="#video" title="Link to this heading"></a></h2>
<p>For a video demonstration of how to do an ROI analysis, click <a class="reference external" href="https://www.youtube.com/watch?v=7CvoaaFI32Y">here</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="AFNI_07_GroupAnalysis.html" class="btn btn-neutral float-left" title="AFNI Tutorial #7: Group Analysis" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="AFNI_09_SurfaceAnalysis.html" class="btn btn-neutral float-right" title="AFNI Tutorial #9: Surface-Based Analysis with SUMA" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Andy Jahn.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>