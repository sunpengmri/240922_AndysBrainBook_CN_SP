<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Frequently Asked Questions &mdash; Andy&#39;s Brain Book 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=f2a433a1"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GIMME (Group Iterative Multiple Model Estimation)" href="../Statistics/GIMME.html" />
    <link rel="prev" title="fASL Tutorial #6: Quantification" href="../ASL/06_fASL_Quantification.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Andy's Brain Book
          </a>
              <div class="version">
                1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Install</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation/fsl_mac_install.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Unix for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_Intro.html">What is Unix?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_01_Navigation.html">Unix Tutorial #1: 目录操作 (Directories and Navigation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_02_CopyRemove.html">Unix Tutorial #2: Copying and Removing Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_03_ReadingTextFiles.html">Unix Tutorial #3: Reading Text Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_04_ShellsVariables.html">Unix Tutorial #4: Shells and Path Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_05_ForLoops.html">Unix Tutorial #5: For-Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_06_IfElse.html">Unix Tutorial #6: Conditional Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_07_Scripting.html">Unix Tutorial #7: Scripting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_08_Sed.html">Unix Tutorial #8: The Sed Command</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unix/Unix_09_AutomatingTheAnalysis.html">Unix Tutorial #9: Automating The Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">fMRI Short Course with FSL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_Intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_01_DataDownload.html">fMRI Tutorial #1: Downloading the Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_02_ExperimentalDesign.html">fMRI Tutorial #2: Overview of The Flanker Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_03_LookingAtTheData.html">fMRI Tutorial #3: Looking at the Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_04_Preprocessing.html">fMRI Tutorial #4: Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_05_1stLevelAnalysis.html">fMRI Tutorial #5: Statistics and Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_06_Scripting.html">fMRI Tutorial #6: Scripting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_07_2ndLevelAnalysis.html">fMRI Tutorial #7: 2nd-Level Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_08_3rdLevelAnalysis.html">fMRI Tutorial #8: 3rd-Level Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_09_ROIAnalysis.html">fMRI Tutorial #9: ROI Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_10_Summary.html">fMRI Tutorial #10: Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fMRI_Short_Course/fMRI_Appendices.html">fMRI Short Course: Appendices</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FreeSurfer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../FreeSurfer/FreeSurfer_Introduction.html">FreeSurfer Short Course</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">E-Prime</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../E-Prime/E-Prime_Overview.html">Overview of E-Prime</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AFNI</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../AFNI/AFNI_Overview.html">AFNI Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SPM</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../SPM/SPM_Overview.html">SPM Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Functional Connectivity with the CONN Toolbox</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../FunctionalConnectivity/CONN_Overview.html">Functional Connectivity and the CONN Toolbox</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parametric Modulation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../PM/PM_Overview.html">Parametric Modulation in SPM, FSL, and AFNI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image Visualization with MRIcroGL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../MRIcroGL/MRIcroGL_Overview.html">Image Visualization with MRIcroGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to the Human Connectome Project (HCP)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../HCP/HCP_Overview.html">Introduction to the Human Connectome Project</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Finite Impulse Response (FIR) Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../FIR/FIR_Overview.html">Finite Impulse Response (FIR)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">fMRI Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Practicals/DesignOptimization.html">Design Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Diffusion Analysis with MRtrix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../MRtrix/MRtrix_Introduction.html">Introduction to MRtrix</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ASL Analysis</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ASL/ASL_Techniques.html">fASL Tutorial #1: Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ASL/fASL_02_Download.html">fASL Tutorial #2: Downloading and Installing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ASL/fASL_03_Task.html">fASL Tutorial #3: The N-Back Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ASL/04_fASL_GUI.html">fASL Tutorial #4: The GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ASL/05_fASL_Results.html">fASL Tutorial #5: Examining the Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ASL/06_fASL_Quantification.html">fASL Tutorial #6: Quantification</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frequently Asked Questions</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#resampling">Resampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#biased-analysis">Biased Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#orientation-problems">Orientation Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-signal-to-noise-ratio-how-can-i-calculate-it">What is Signal-to-Noise Ratio? How can I calculate it?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-can-i-calculate-the-number-of-voxels-in-a-mask">How can I calculate the number of voxels in a mask?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-can-i-unwarp-my-data">How can I unwarp my data?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#steps-for-field-map-unwarping">Steps for field-map unwarping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#step-0-create-brain-mask-of-magnitude-image">Step 0: Create brain mask of magnitude image</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-1-create-fieldmap">Step 1: Create fieldmap</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-2-apply-fieldmap-with-fugue-to-unwarp-functional-images">Step 2: Apply fieldmap with FUGUE to unwarp functional images</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#unwarping-with-blip-up-blip-down-images">Unwarping with blip-up/blip-down images</a></li>
<li class="toctree-l3"><a class="reference internal" href="#related-readings">Related Readings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#how-do-i-merge-multiple-rois-into-a-single-file">How do I merge multiple ROIs into a Single File?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-do-i-extract-the-voxel-coordinates-for-an-roi">How do I extract the voxel coordinates for an ROI?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-in-the-header-of-a-nifti-file">What is in the header of a NIFTI file?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#i-get-the-message-error-could-not-resample-when-running-afni-s-align-epi-anat-py-how-do-i-fix-this">I get the message “ERROR: Could not resample” when running AFNI’s align_epi_anat.py. How do I fix this?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#other-questions">Other Questions</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Statistics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Statistics/GIMME.html">GIMME (Group Iterative Multiple Model Estimation)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Open Science</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../OpenScience/OS_Overview.html">Open Science</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Normalization Tools (ANTs)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ANTs/ANTs_Overview.html">Advanced Normalization Tools (ANTs)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tract-Based Spatial Statistics (TBSS)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../TBSS/TBSS_Overview.html">Introduction to Tract-Based Spatial Statistics (TBSS)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Statistics for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Stats/Stats_Overview.html">Statistics for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Machine Learning for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ML/ML_Overview.html">Machine Learning for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Slicer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Slicer/Slicer_Overview.html">Slicer Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CAT12</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CAT12/CAT12_Overview.html">Voxel-Based Morphometry with CAT12</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Using the Supercomputer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Supercomputer/Supercomputer_Overview.html">Introduction to Supercomputing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Matlab for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Matlab/Matlab_Overview.html">Matlab for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ITK-Snap</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ITK-Snap/ITK-Snap_Overview.html">ITK-Snap_Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../PythonForNeuroimagers/PythonForNeuroimagers_Overview.html">Python for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Meta-Analysis for fMRI</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../MetaAnalysis/MetaAnalysis_Overview.html">Meta-Analysis for Neuroimagers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Andy's Brain Book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Frequently Asked Questions</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/FrequentlyAskedQuestions/FrequentlyAskedQuestions.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="frequently-asked-questions">
<span id="frequentlyaskedquestions"></span><h1>Frequently Asked Questions<a class="headerlink" href="#frequently-asked-questions" title="Link to this heading"></a></h1>
<p>This is a list of common questions that I am asked. I have found that most questions can be organized into categories such as Resampling, Cluster Correction, Normalization, and so on. Some of these questions may eventually be folded into the fMRI Concepts section.</p>
<section id="resampling">
<h2>Resampling<a class="headerlink" href="#resampling" title="Link to this heading"></a></h2>
<p>Question: What is resampling?</p>
<p>Answer: Resampling means changing either the resolution, dimensions, or both the resolution and dimensions of an image. A typical fMRI image is composed of voxels, which are like the pixels that make up your computer screen, but in three dimensions. For example, a common voxel size is 3 by 3 by 4 millimeters.</p>
<figure class="align-default" id="id1">
<img alt="../_images/Voxel_Example.png" src="../_images/Voxel_Example.png" />
<figcaption>
<p><span class="caption-text">An fMRI image is composed of cubes called voxels (lower right). Each of these cubes contains a single number representing the signal measured at that voxel. Voxels can either be isotropic, with dimensions of equal lengths, or anisotropic, with at least one dimension either longer or shorter than the other dimensions. One common use of resampling is to make the dimensions of the voxel either shorter or longer, which in turn creates larger or smaller voxels. Larger voxels lead to a lower-resolution image, and smaller voxels will lead to a higher-resolution image.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>You can resample an image using several different methods. Let’s start with the nearest neighbor method, which is the easiest to illustrate. Imagine that we have a 4x4 grid with a number in each square, and that we want to resample it to a 3x3 grid. In the animation below, we superimpose a 3x3 grid on the original 4x4 grid and then find which number is closest to the center of the new square. In the upper left corner, for example, the number 8 is closest to the center of the new square. As a result, the new square will now contain the value 8.</p>
<figure class="align-default">
<img alt="../_images/NearestNeighbor_Example.gif" src="../_images/NearestNeighbor_Example.gif" />
</figure>
<p>For example, let’s say that you created a mask in FSL, and you would like to extract the data from a statistical map. You can use flirt to resample the mask to the statistical image:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">flirt</span> <span class="o">-</span><span class="ow">in</span> <span class="n">mask</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">ref</span> <span class="n">stats</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">out</span> <span class="n">mask_RS</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">applyxfm</span>
</pre></div>
</div>
<p>Or in AFNI:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dresample</span> <span class="o">-</span><span class="nb">input</span> <span class="n">mask</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">master</span> <span class="n">stats</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">prefix</span> <span class="n">mask_RS</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span>
</pre></div>
</div>
<p>And you would then be able to use an ROI extraction command, such as 3dmaskave or fslstats, to extract data from the mask.</p>
<p>In order to resample an image to an isotropic voxel size, such as 3x3x3, you can use the following options with flirt:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">flirt</span> <span class="o">-</span><span class="ow">in</span> <span class="n">volume</span><span class="o">.</span><span class="n">nii</span> <span class="o">-</span><span class="n">ref</span> <span class="n">volume</span><span class="o">.</span><span class="n">nii</span> <span class="o">-</span><span class="n">applyisoxfm</span> <span class="mf">3.0</span> <span class="o">-</span><span class="n">nosearch</span> <span class="o">-</span><span class="n">out</span> <span class="n">volume_3x3x3</span><span class="o">.</span><span class="n">nii</span>
</pre></div>
</div>
<p>To resample to an anisotropic voxel resolution, you can use AFNI’s 3dresample command, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dresample</span> <span class="o">-</span><span class="nb">input</span> <span class="n">volume</span><span class="o">.</span><span class="n">nii</span> <span class="o">-</span><span class="n">prefix</span> <span class="n">output_volume</span><span class="o">.</span><span class="n">nii</span> <span class="o">-</span><span class="n">dxyz</span> <span class="mi">1</span> <span class="mf">0.8</span> <span class="mf">1.5</span>
</pre></div>
</div>
<p>Which will resample the voxels to have a size of 1x0.8x1.5mm, in this example.</p>
<p>SPM uses the GUI to resample the images; the steps for this procedure can be found in <a class="reference external" href="https://andysbrainbook.readthedocs.io/en/latest/SPM/SPM_Short_Course/SPM_09_ROIAnalysis.html#using-the-command-line-for-roi-analysis">this chapter</a>.</p>
<p>For an overview of this topic, see <a class="reference external" href="https://www.youtube.com/watch?v=rvW-D5o3ALA">this video</a>.</p>
</section>
<section id="biased-analysis">
<h2>Biased Analysis<a class="headerlink" href="#biased-analysis" title="Link to this heading"></a></h2>
<p>Question: What is a biased analysis? How do you avoid doing them?</p>
<p>To give an example of a biased analysis, imagine that we wanted to test whether drinking Four Loko helps undergraduates do better on their exams. Let’s say that we observed which students showed an improvement, and then ran our final group-level analysis on only those students. Obviously this would be a biased analysis, since we’re only focusing on those subjects that have the effect we’re looking for; it’s no longer a truly random sample.</p>
<p>Circular analyses can also happen with imaging data, although it’s not as apparent when it happens. This was first pointed out in a study which examined activity in the fusiform face area in response to different stimuli. They extracted data from each condition’s significant voxels and discovered a pattern of selective activity. However, it was pointed out that if you chose an ROI outside of the brain which happened to contain significant voxels just by chance, and ran the same tests on those voxels, you would get the same pattern - which clearly shouldn’t happen. When they reran the analysis using independent ROIs, they found a pattern of noise - which you would expect with a non-brain ROI. When they ran an unbiased ROI analysis on the original data, they found that the original pattern disappeared.</p>
<p>Let’s see exactly how biased ROIs lead to inflated effect sizes. Here is a z-score map showing our group-level effects. If we zoom in, we can see the boundaries of each individual voxel, with a range of z-scores from 0 to 3. Assume that there is a real effect in the brain outlined in orange. If we extracted the parameter estimates for each subject from those voxels, the effect would be 0.3 – with some variation around that value. Now assume that we threshold our image at an uncorrected level of p&lt;0.05, or a z-score of 1.65. The voxels highlighted in red are the only ones that pass that threshold. Here’s the important part: notice that this region overlaps with some of the true effect voxels, but that it includes some noise voxels as well. Because the region by definition can only include voxels passing a certain threshold, it will only contain noise voxels that are above that threshold, which biases the effect to be larger than the true effect. If we used an independent ROI, for example with cross-validation, we would create a region that probably contains some true effect voxels, and also some noise voxels – but these noise voxels will not be biased to be artificially high or low. In this example the unbiased effect is slightly lower than the true effect, but in theory it could be higher or lower – it just won’t be biased either way.</p>
<figure class="align-default">
<img alt="../_images/BiasedAnalysis.png" src="../_images/BiasedAnalysis.png" />
</figure>
<p>There are two problems with those arguments. First, the magnitude of the effect is just as important as detecting whether the effect is there, and biased analyses will systematically overestimate it. Why? Because small studies by definition can only detect large effects. The second is that if you publish a biased analysis, the reader may assume that it is an inferential analysis, even if it includes caveats about how it was done. If you absolutely insist on presenting them in a figure, at least don’t include error bars.</p>
<p>We’ve only touched on a couple of different ways to do biased analyses, but there are other ways too - and you need to be on the lookout for them. Let’s say that you use an anterior cingulate cortex ROI for your confirmatory analysis - meaning that you selected the ROI beforehand, regardless of what the whole-brain results look like - but the results don’t pass correction. You then look at the whole-brain map, and see this. You then decide to use an ROI located more in the pre-SMA. This is also a biased analysis, because now you know where your effect is before you decide where to extract from.</p>
</section>
<section id="orientation-problems">
<h2>Orientation Problems<a class="headerlink" href="#orientation-problems" title="Link to this heading"></a></h2>
<p>Question: When I open my image in a viewer, the axes don’t look right. How can I change it to a more reasonable orientation, such as LPI?</p>
<p>First, let’s define the acronyms often used when discussing orientation. Remember that fMRI data is three-dimensional, and that each image has an <strong>origin</strong> which specifies the coordinates of X=0, Y=0, and Z=0. Usually the <strong>anterior commissure</strong>, a bundle of connective fibers just below the fornix, is set as the origin.</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../_images/AnteriorCommissure.png"><img alt="../_images/AnteriorCommissure.png" src="../_images/AnteriorCommissure.png" style="width: 455.20000000000005px; height: 176.20000000000002px;" /></a>
</figure>
<p>The orientation of the image indicates which direction relative to the origin is positive or negative, and the orientation is specified by a triplet of letters. For example, LPI signifies that the direction is negative to the left of the anterior commissure, and positive to the right; negative behind, and positive forward; and negative below, positive above. In this orientation, coordinates of X=-3, Y=18, Z=34 would mean that the crosshair is centered on a voxel that is, relative to the anterior commisure, 3 millimeters to the left, 18 millimeters forward, and 34 millimeters above - approximately in the left dorsal anterior cingulate.</p>
<p>Sometimes the orientations are flipped along one or more of the axes, resulting in orientations such as RPI or RAI. As long as all of the data is processed the same way and all of the images have the same orientation, this usually isn’t a problem. However, if you have an image with a different orientation, you will have to change it.</p>
<p>This can be done with FSL’s fslswapdim command. Let’s demonstrate this with the <a class="reference external" href="https://openneuro.org/datasets/ds000214/versions/00001">EUPD Cyberball</a> dataset from Openneuro.org. If you download the anatomical and functional data for subject EESS001, you will notice that although the functional data looks OK, the anatomical data’s orientations appear to be flipped: The coronal section is displayed as though it’s on its side, and the other views look odd:</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../_images/anat_flipped.png"><img alt="../_images/anat_flipped.png" src="../_images/anat_flipped.png" style="width: 870.4000000000001px; height: 295.2px;" /></a>
</figure>
<p>To fix this, type the following command:</p>
<p>fslswapdim sub-EESS001_anat_sub-EESS001_T1w.nii.gz RL PA IS anat_reorient.nii</p>
<p>When you open the reoriented image, it looks as though it’s in the correct orientation. Overlay the functional image on top of it to make sure that all of the images are now in the same orientation.</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../_images/anat_reorient.png"><img alt="../_images/anat_reorient.png" src="../_images/anat_reorient.png" style="width: 906.8000000000001px; height: 361.20000000000005px;" /></a>
</figure>
</section>
<section id="what-is-signal-to-noise-ratio-how-can-i-calculate-it">
<h2>What is Signal-to-Noise Ratio? How can I calculate it?<a class="headerlink" href="#what-is-signal-to-noise-ratio-how-can-i-calculate-it" title="Link to this heading"></a></h2>
</section>
<section id="how-can-i-calculate-the-number-of-voxels-in-a-mask">
<h2>How can I calculate the number of voxels in a mask?<a class="headerlink" href="#how-can-i-calculate-the-number-of-voxels-in-a-mask" title="Link to this heading"></a></h2>
<p>Let’s say you have two masks in an image, labeled A and B. Mask A is composed of 1’s, and Mask B is composed of 2’s. If these masks are saved into one image called <code class="docutils literal notranslate"><span class="pre">ROIs.nii.gz</span></code>, and they were created from a template called <code class="docutils literal notranslate"><span class="pre">ROI_Template.nii.gz</span></code>, you can use the command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fslstats</span> <span class="o">-</span><span class="n">K</span> <span class="n">ROIs</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="n">ROI_Template</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">V</span>
</pre></div>
</div>
<p>Which will return two numbers per mask. The first number is the number of voxels, and the second number is the volume, in cubic millimeters. For example, if one of my masks was 9 voxels large and the other one was 15 voxels, with a 2x2x2mm resolution (or 8 cubic millimeters per voxel), the output would look like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">9</span> <span class="mf">72.000000</span> <span class="mi">15</span> <span class="mf">120.000000</span>
</pre></div>
</div>
</section>
<section id="how-can-i-unwarp-my-data">
<h2>How can I unwarp my data?<a class="headerlink" href="#how-can-i-unwarp-my-data" title="Link to this heading"></a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>I will expand upon this in a more developed section; the following are some quick notes, so that I don’t forget how I did this.</p>
</div>
<p>Imaging data is often warped because of magnetic field inhomogeneities (also known as B0 inhomogeneities). The data can be unwarped using field maps, which detect where the inhomogeneities are located.</p>
<section id="steps-for-field-map-unwarping">
<h3>Steps for field-map unwarping<a class="headerlink" href="#steps-for-field-map-unwarping" title="Link to this heading"></a></h3>
<section id="step-0-create-brain-mask-of-magnitude-image">
<h4>Step 0: Create brain mask of magnitude image<a class="headerlink" href="#step-0-create-brain-mask-of-magnitude-image" title="Link to this heading"></a></h4>
<p>The first step is to create a map of the voxels that we will use for unwarping. You can use any skull-stripping program you like, but for now, we will use the relatively fast <code class="docutils literal notranslate"><span class="pre">bet2</span></code> command from FSL:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bet2</span> <span class="n">MagnitudeImage</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">f</span> <span class="mf">0.7</span>
</pre></div>
</div>
<p>Play around with the fractional intensity threshold to generate a brain mask that is restricted just to the brain voxels (i.e., err on the side of excluding some brain voxels rather than including any non-brain voxels).</p>
</section>
<section id="step-1-create-fieldmap">
<h4>Step 1: Create fieldmap<a class="headerlink" href="#step-1-create-fieldmap" title="Link to this heading"></a></h4>
<p>The next step will create the fieldmap using FSL’s <code class="docutils literal notranslate"><span class="pre">fsl_prepare_fieldmap</span></code> command. This command includes an option, SIEMENS, that is optimized for Siemens scanners:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fsl_prepare_fieldmap</span> <span class="n">SIEMENS</span> <span class="n">phaseImage</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="n">MagnitudeImage_brain</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="n">fieldmap</span><span class="o">.</span><span class="n">nii</span> <span class="mf">2.65</span>
</pre></div>
</div>
<p>This last parameter (2.65) is the delta TE, which you will need to verify on your scanner. I believe this is the default for Siemens, but small deviations don’t seem to make that much of a difference in the fieldmap.</p>
<p>Check the fieldmap in an image viewer; it should be brighter in the orbitofrontal and inferior temporal areas, representing where there is greater field inhomogeneity and greater signal loss.</p>
</section>
<section id="step-2-apply-fieldmap-with-fugue-to-unwarp-functional-images">
<h4>Step 2: Apply fieldmap with FUGUE to unwarp functional images<a class="headerlink" href="#step-2-apply-fieldmap-with-fugue-to-unwarp-functional-images" title="Link to this heading"></a></h4>
<p>Unwarping the images requires a parameter called “echo spacing”, the distance between echoes in echo planar images. If you have acquired two magnitude fieldmap images, echo spacing can be calculated by subracting the echo time of the first magnitude image from the echo time of the second magnitude image.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">--dwell</span></code> option of the commend below specifies the dwell time, which is your echo spacing divided by your acceleration factor. For example, if your echo spacing time is 0.00072 seconds, and your acceleration factor is 4, you would calculate 0.00072 / 4 = 0.00018 to create your dwell time value:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fugue</span> <span class="o">-</span><span class="n">i</span> <span class="n">fMRI_Image</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">--</span><span class="n">dwell</span><span class="o">=</span><span class="mf">.0.00018</span> <span class="o">--</span><span class="n">unwarpdir</span><span class="o">=</span><span class="n">y</span><span class="o">-</span> <span class="o">--</span><span class="n">loadfmap</span><span class="o">=</span><span class="n">fieldmap</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">u</span> <span class="n">fMRI_Unwarped</span><span class="o">.</span><span class="n">nii</span>
</pre></div>
</div>
<p>The option unwarpdir indicates the direction for unwarping our data. For example, if the fMRI data was acquired with a phase-encoding direction of Anterior-to-Posterior, this is along the y axis; the unwarping would therefore be in the opposite direction, which is specified with y-.</p>
<p>Check the output image to see whether it appears to have been unwarped correctly.</p>
</section>
</section>
<section id="unwarping-with-blip-up-blip-down-images">
<h3>Unwarping with blip-up/blip-down images<a class="headerlink" href="#unwarping-with-blip-up-blip-down-images" title="Link to this heading"></a></h3>
<p>Another way to unwarp the data is with <strong>blip-up/blip-down</strong> images. Usually these are acquired in the Anterior-to-Posterior (AP) and Posterior-to-Anterior (PA) directions, with one of the directions being used to acquire your functional runs. For example, let’s say that you have two images labeled AP.nii.gz and PA.nii.gz: The former contains three volumes, and the latter contains three volumes. AP images typically look more “smushed” near the frontal pole, and PA images are more smeared outwards at the frontal areas.</p>
<p>You can use FSL’s topup to fix these. (Apply motion correction before or after?) First, merge the two phase-encoded images together with <code class="docutils literal notranslate"><span class="pre">fslmerge</span> <span class="pre">-t</span> <span class="pre">AP_PA_b0.nii.gz</span> <span class="pre">AP.nii.gz</span> <span class="pre">PA.nii.gz</span></code>.</p>
<p>Then use topup to create a fieldmap:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">topup</span> <span class="o">--</span><span class="n">imain</span><span class="o">=</span><span class="n">AP_PA_b0</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">--</span><span class="n">datain</span><span class="o">=</span><span class="n">acqparams</span><span class="o">.</span><span class="n">txt</span> <span class="o">--</span><span class="n">config</span><span class="o">=</span><span class="n">b02b0</span><span class="o">.</span><span class="n">cnf</span> <span class="o">--</span><span class="n">out</span><span class="o">=</span><span class="n">topup_AP_PA_b0</span>
</pre></div>
</div>
<p>In which config is a file that is provided by default by FSL (e.g., you don’t have to create it; you can type this command from anywhere), and acqparams is a text file that contains the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="o">-</span><span class="mi">1</span> <span class="mi">0</span> <span class="mf">0.0665</span>
<span class="mi">0</span> <span class="o">-</span><span class="mi">1</span> <span class="mi">0</span> <span class="mf">0.0665</span>
<span class="mi">0</span> <span class="o">-</span><span class="mi">1</span> <span class="mi">0</span> <span class="mf">0.0665</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mf">0.0665</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mf">0.0665</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mf">0.0665</span>
</pre></div>
</div>
<p>The way to read this file is, in columns from left to right:</p>
<ol class="arabic simple">
<li><p>+RL</p></li>
<li><p>+PA</p></li>
<li><p>+IS (This is a guess)</p></li>
<li><p>Readout time, defined as the time from acquisition of the center of the first echo to the center of the last. You can also calculate it with the formula: ReadoutTime = [EchoSpacing (in ms)] * [EPI Factor] * 0.001</p></li>
</ol>
<p>This will create a field map, which can be applied to the fMRI data with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">applytopup</span> <span class="o">--</span><span class="n">imain</span><span class="o">=</span><span class="n">fMRI</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span> <span class="o">--</span><span class="n">topup</span><span class="o">=</span><span class="n">topup_AP_PA_b0</span> <span class="o">--</span><span class="n">datain</span><span class="o">=</span><span class="n">acqparams</span><span class="o">.</span><span class="n">txt</span> <span class="o">--</span><span class="n">inindex</span><span class="o">=</span><span class="mi">1</span> <span class="o">--</span><span class="n">out</span><span class="o">=</span><span class="n">fMRI_unwarped</span> <span class="o">--</span><span class="n">method</span><span class="o">=</span><span class="n">jac</span>
</pre></div>
</div>
</section>
<section id="related-readings">
<h3>Related Readings<a class="headerlink" href="#related-readings" title="Link to this heading"></a></h3>
<p>See these websites for more details about field-map unwarping a functional image.</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup/TopupUsersGuide#Configuration_files">FSL topup guide</a></p></li>
<li><p><a class="reference external" href="http://ftp.nmr.mgh.harvard.edu/pub/dist/freesurfer/tutorial_packages/centos6/fsl_507/doc/wiki/topup(2f)TopupUsersGuide.html">More detailed topup guide</a></p></li>
<li><p><a class="reference external" href="https://lcni.uoregon.edu/kb-articles/kb-0003">Lewis Center for neuroimaging: Using field maps</a></p></li>
</ol>
</section>
</section>
<section id="how-do-i-merge-multiple-rois-into-a-single-file">
<h2>How do I merge multiple ROIs into a Single File?<a class="headerlink" href="#how-do-i-merge-multiple-rois-into-a-single-file" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Merge all of the publication ROIs into one file using fslmaths to add them together (fslmerge, on the other hand, will concatenate the volumes in time, and each ROI will be in a separate volume);</p></li>
<li><p>Merge the other ROIs using step 1 above;</p></li>
<li><p>Multiply the merged theoretical ROI dataset by 2, using fslmaths (e.g., fslmaths theoretical_ROIs.nii -mul 2 theoretical_ROIs_2s.nii);</p></li>
<li><p>Multiply the merge Neurosynth ROI dataset by 3 (fslmaths neurosynth_ROIs.nii -mul 3 neurosynth_ROIs_3s.nii);</p></li>
<li><p>Merge all of the datasets together using fslmaths (e.g., fslmaths pub_ROIs.nii -add theoretical_ROIs_2s.nii -add neurosynth_ROIs_3s.nii all_ROIs.nii)</p></li>
</ol>
<p>View it in fsleyes and see if that is what you want.</p>
</section>
<section id="how-do-i-extract-the-voxel-coordinates-for-an-roi">
<h2>How do I extract the voxel coordinates for an ROI?<a class="headerlink" href="#how-do-i-extract-the-voxel-coordinates-for-an-roi" title="Link to this heading"></a></h2>
<p>If the atlas is in MNI space, you can use a command like AFNI’s 3dmaskdump. First, save the mask using the methods shown here: <a class="reference external" href="https://www.youtube.com/watch?v=Vaj7BBxqXt0">https://www.youtube.com/watch?v=Vaj7BBxqXt0</a></p>
<p>Then type the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dmaskdump</span> <span class="o">-</span><span class="n">noijk</span> <span class="o">-</span><span class="n">xyz</span> <span class="o">-</span><span class="n">nozero</span> <span class="o">-</span><span class="n">mask</span> <span class="n">yourMask</span><span class="o">.</span><span class="n">nii</span> <span class="n">yourMask</span><span class="o">.</span><span class="n">nii</span>
</pre></div>
</div>
<p>It should generate a series of numbers, with the first 3 representing the MNI coordinates of each voxel. Note that these are in RAI orientation, so you will have to multiply the first two columns by -1 in order to convert it to LPI orientation (which is the standard used by most people).</p>
</section>
<section id="what-is-in-the-header-of-a-nifti-file">
<h2>What is in the header of a NIFTI file?<a class="headerlink" href="#what-is-in-the-header-of-a-nifti-file" title="Link to this heading"></a></h2>
<p>When an fMRI images is acquired, several pieces of information are stored in its <strong>header</strong>, which is like a list of ingredients on the side of a box. For example, using the FSL command <code class="docutils literal notranslate"><span class="pre">fslinfo</span></code> on a functional dataset might return something like this (comments are after the # symbol):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_type</span>     <span class="n">INT16</span> <span class="c1">#The decimal precision of the data; e.g., INT16 means that it is in Integer format (i.e., no decimals), and can store values between –32768 and 32768.</span>
<span class="n">dim1</span>          <span class="mi">64</span> <span class="c1"># Number of voxels in the x-dimension (i.e., left-to-right)</span>
<span class="n">dim2</span>          <span class="mi">64</span> <span class="c1"># Number of voxels in the y-dimension (i.e., front-to-back)</span>
<span class="n">dim3</span>          <span class="mi">42</span> <span class="c1"># Number of voxels in the z-dimension (i.e., bottom-to-top; in most acquistions, these are the **slices**)</span>
<span class="n">dim4</span>          <span class="mi">180</span> <span class="c1"># Number of time-points; in other words, the number of volumes that have been concatenated together into a time-series</span>
<span class="n">datatype</span>      <span class="mi">4</span>
<span class="n">pixdim1</span>               <span class="mf">3.000000</span> <span class="c1"># Size of each voxel in the x-dimension, in millimeters</span>
<span class="n">pixdim2</span>               <span class="mf">3.000000</span> <span class="c1"># Size of each voxel in the y-dimension, in millimeters</span>
<span class="n">pixdim3</span>               <span class="mf">3.300000</span> <span class="c1"># Size of each voxel in the z-dimension, in millimeters</span>
<span class="n">pixdim4</span>               <span class="mf">2.100000</span> <span class="c1"># Size of the time-step, or TR; in other words, the time it takes to acquire each volume</span>
<span class="n">cal_max</span>               <span class="mf">0.000000</span>
<span class="n">cal_min</span>               <span class="mf">0.000000</span>
<span class="n">file_type</span>     <span class="n">NIFTI</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span>
</pre></div>
</div>
<p>Given this, annotate the output of this same command when applied to an anatomical image (hint: It is a single volume):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_type</span>     <span class="n">INT16</span>
<span class="n">dim1</span>          <span class="mi">256</span>
<span class="n">dim2</span>          <span class="mi">256</span>
<span class="n">dim3</span>          <span class="mi">160</span>
<span class="n">dim4</span>          <span class="mi">1</span>
<span class="n">datatype</span>      <span class="mi">4</span>
<span class="n">pixdim1</span>               <span class="mf">1.000006</span>
<span class="n">pixdim2</span>               <span class="mf">1.000000</span>
<span class="n">pixdim3</span>               <span class="mf">1.000000</span>
<span class="n">pixdim4</span>               <span class="mf">1.700000</span>
<span class="n">cal_max</span>               <span class="mf">0.000000</span>
<span class="n">cal_min</span>               <span class="mf">0.000000</span>
<span class="n">file_type</span>     <span class="n">NIFTI</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span>
</pre></div>
</div>
<p>It is common to report the anatomical x- and y-dimensions as the field of view, or FOV, in the Methods section of neuroimaging papers. Since the x- and y- dimensions for anatomical images are usually the same, the FOV is typically reported as a single number, in centimeters, that is supposed to represent each of them separately. For example, in the output above, the FOV might be reported as “25.6cm”.</p>
<p>You can output even more of the header by using a command like <code class="docutils literal notranslate"><span class="pre">fslhd</span></code>. For example, some datasets may report this in the <code class="docutils literal notranslate"><span class="pre">descrip</span></code> field at the bottom of the output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">descrip</span>               <span class="n">TE</span><span class="o">=</span><span class="mf">4.2</span><span class="p">;</span><span class="n">Time</span><span class="o">=</span><span class="mf">123931.290</span><span class="p">;</span><span class="n">phase</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
<p>Other pieces of information, such as the flip angle, are not usually stored in the header and must be extracted from the protocol located in the computer that ran the fMRI scan.</p>
</section>
<section id="i-get-the-message-error-could-not-resample-when-running-afni-s-align-epi-anat-py-how-do-i-fix-this">
<h2>I get the message “ERROR: Could not resample” when running AFNI’s align_epi_anat.py. How do I fix this?<a class="headerlink" href="#i-get-the-message-error-could-not-resample-when-running-afni-s-align-epi-anat-py-how-do-i-fix-this" title="Link to this heading"></a></h2>
<p>This can be due to either the raw anatomical or raw functional image being in TLRC as opposed to ORIG space. (I’m not sure why this happens, but it does sometimes.) See if this <code class="docutils literal notranslate"><span class="pre">3dinfo</span></code> command returns the string “TLRC” for any of the raw images:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">dinfo</span> <span class="o">-</span><span class="n">space</span> <span class="n">funcImage</span><span class="o">.</span><span class="n">nii</span>
</pre></div>
</div>
<p>If it returns “TLRC”, type the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">drefit</span> <span class="o">-</span><span class="n">space</span> <span class="n">ORIG</span> <span class="n">funcImage</span><span class="o">.</span><span class="n">nii</span>
</pre></div>
</div>
<p>And then rerun your AFNI proc script or align_epi_anat.py command.</p>
</section>
<section id="other-questions">
<h2>Other Questions<a class="headerlink" href="#other-questions" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p>What is the difference between a functional and a structural image?</p></li>
<li><p>Where do the fMRI templates come from? When should one use a template other than the default?</p></li>
<li><p>What are the types of images that one can generate from the scanner, and how are they different? What questions can they answer?</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../ASL/06_fASL_Quantification.html" class="btn btn-neutral float-left" title="fASL Tutorial #6: Quantification" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../Statistics/GIMME.html" class="btn btn-neutral float-right" title="GIMME (Group Iterative Multiple Model Estimation)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Andy Jahn.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>