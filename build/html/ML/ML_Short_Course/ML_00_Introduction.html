<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Machine Learning: Introduction to Basic Terms and Concepts &mdash; Andy&#39;s Brain Book 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b76e3c8a" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Machine Learning Tutorial #1: Basic Example with Support Vector Machines" href="ML_01_Brown_Example.html" />
    <link rel="prev" title="Machine Learning for Neuroimagers" href="../ML_Overview.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Andy's Brain Book
          </a>
              <div class="version">
                1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Install</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation/fsl_mac_install.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Unix for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_Intro.html">What is Unix?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_01_Navigation.html">Unix Tutorial #1: 目录操作 (Directories and Navigation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_02_CopyRemove.html">Unix Tutorial #2: Copying and Removing Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_03_ReadingTextFiles.html">Unix Tutorial #3: Reading Text Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_04_ShellsVariables.html">Unix Tutorial #4: Shells and Path Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_05_ForLoops.html">Unix Tutorial #5: For-Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_06_IfElse.html">Unix Tutorial #6: Conditional Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_07_Scripting.html">Unix Tutorial #7: Scripting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_08_Sed.html">Unix Tutorial #8: The Sed Command</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unix/Unix_09_AutomatingTheAnalysis.html">Unix Tutorial #9: Automating The Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">fMRI Short Course with FSL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_Intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_01_DataDownload.html">fMRI Tutorial #1: Downloading the Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_02_ExperimentalDesign.html">fMRI Tutorial #2: Overview of The Flanker Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_03_LookingAtTheData.html">fMRI Tutorial #3: Looking at the Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_04_Preprocessing.html">fMRI Tutorial #4: Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_05_1stLevelAnalysis.html">fMRI Tutorial #5: Statistics and Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_06_Scripting.html">fMRI Tutorial #6: Scripting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_07_2ndLevelAnalysis.html">fMRI Tutorial #7: 2nd-Level Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_08_3rdLevelAnalysis.html">fMRI Tutorial #8: 3rd-Level Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_09_ROIAnalysis.html">fMRI Tutorial #9: ROI Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_10_Summary.html">fMRI Tutorial #10: Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fMRI_Short_Course/fMRI_Appendices.html">fMRI Short Course: Appendices</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FreeSurfer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../FreeSurfer/FreeSurfer_Introduction.html">FreeSurfer Short Course</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">E-Prime</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../E-Prime/E-Prime_Overview.html">Overview of E-Prime</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AFNI</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../AFNI/AFNI_Overview.html">AFNI Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SPM</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../SPM/SPM_Overview.html">SPM Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Functional Connectivity with the CONN Toolbox</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionalConnectivity/CONN_Overview.html">Functional Connectivity and the CONN Toolbox</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parametric Modulation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PM/PM_Overview.html">Parametric Modulation in SPM, FSL, and AFNI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image Visualization with MRIcroGL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../MRIcroGL/MRIcroGL_Overview.html">Image Visualization with MRIcroGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to the Human Connectome Project (HCP)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../HCP/HCP_Overview.html">Introduction to the Human Connectome Project</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Finite Impulse Response (FIR) Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../FIR/FIR_Overview.html">Finite Impulse Response (FIR)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">fMRI Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Practicals/DesignOptimization.html">Design Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Diffusion Analysis with MRtrix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../MRtrix/MRtrix_Introduction.html">Introduction to MRtrix</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ASL Analysis</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/ASL_Techniques.html">fASL Tutorial #1: Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/fASL_02_Download.html">fASL Tutorial #2: Downloading and Installing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/fASL_03_Task.html">fASL Tutorial #3: The N-Back Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/04_fASL_GUI.html">fASL Tutorial #4: The GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/05_fASL_Results.html">fASL Tutorial #5: Examining the Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ASL/06_fASL_Quantification.html">fASL Tutorial #6: Quantification</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frequently Asked Questions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../FrequentlyAskedQuestions/FrequentlyAskedQuestions.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Statistics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Statistics/GIMME.html">GIMME (Group Iterative Multiple Model Estimation)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Open Science</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../OpenScience/OS_Overview.html">Open Science</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Normalization Tools (ANTs)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ANTs/ANTs_Overview.html">Advanced Normalization Tools (ANTs)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tract-Based Spatial Statistics (TBSS)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../TBSS/TBSS_Overview.html">Introduction to Tract-Based Spatial Statistics (TBSS)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Statistics for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Stats/Stats_Overview.html">Statistics for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Machine Learning for Neuroimagers</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../ML_Overview.html">Machine Learning for Neuroimagers</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../ML_Overview.html#overview">Overview</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Machine Learning: Introduction to Basic Terms and Concepts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#what-is-machine-learning">What is Machine Learning?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#machine-learning-in-neuroimaging">Machine Learning in Neuroimaging</a></li>
<li class="toctree-l4"><a class="reference internal" href="#support-vector-machines">Support Vector Machines</a></li>
<li class="toctree-l4"><a class="reference internal" href="#video">Video</a></li>
<li class="toctree-l4"><a class="reference internal" href="#next-steps">Next Steps</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ML_01_Brown_Example.html">Machine Learning Tutorial #1: Basic Example with Support Vector Machines</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_02_Haxby_Intro_Download.html">Machine Learning Tutorial #2: The Haxby Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_03_Haxby_Preprocessing.html">Machine Learning Tutorial #3: Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_04_Haxby_Timing.html">Machine Learning Tutorial #4: Creating the Timing Files</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_05_Haxby_MVPA.html">Machine Learning Tutorial #5: MVPA Analysis with The Decoding Toolbox</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_06_Haxby_Scripting.html">Machine Learning Tutorial #6: Scripting</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_07_Haxby_GroupAnalysis.html">Machine Learning Tutorial #7: Group Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_08_Haxby_NonParametric.html">Machine Learning Tutorial #8: Non-Parametric Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_09_RSA.html">Machine Learning Tutorial #9: Representational Similarity Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="ML_10_Hyperalignment.html">Machine Learning Tutorial #10: Hyperalignment</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Slicer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Slicer/Slicer_Overview.html">Slicer Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CAT12</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../CAT12/CAT12_Overview.html">Voxel-Based Morphometry with CAT12</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Using the Supercomputer</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Supercomputer/Supercomputer_Overview.html">Introduction to Supercomputing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Matlab for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Matlab/Matlab_Overview.html">Matlab for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ITK-Snap</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ITK-Snap/ITK-Snap_Overview.html">ITK-Snap_Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python for Neuroimagers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PythonForNeuroimagers/PythonForNeuroimagers_Overview.html">Python for Neuroimagers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Meta-Analysis for fMRI</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../MetaAnalysis/MetaAnalysis_Overview.html">Meta-Analysis for Neuroimagers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Andy's Brain Book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../ML_Overview.html">Machine Learning for Neuroimagers</a></li>
      <li class="breadcrumb-item active">Machine Learning: Introduction to Basic Terms and Concepts</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/ML/ML_Short_Course/ML_00_Introduction.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="machine-learning-introduction-to-basic-terms-and-concepts">
<span id="ml-00-introduction"></span><h1>Machine Learning: Introduction to Basic Terms and Concepts<a class="headerlink" href="#machine-learning-introduction-to-basic-terms-and-concepts" title="Link to this heading"></a></h1>
<hr class="docutils" />
<section id="what-is-machine-learning">
<h2>What is Machine Learning?<a class="headerlink" href="#what-is-machine-learning" title="Link to this heading"></a></h2>
<p>Machine Learning is a method of using data to train a classifier; this is called <strong>training data</strong>. The classifier is then provided with new data (also known as <strong>testing data</strong>), and then it decides whether a new data point belongs to one category or another. The classifier’s performance is judged by its accuracy - how many of the testing data points it manages to classify correctly.</p>
<p>The training data has one or more <strong>features</strong> that are used to train the classifier. These features can be any characteristic; for example, height and hair length. For example, you have probably met several thousand people in your life, and you’ve seen many thousands more in movies, pictures, and magazines. Over time, you’ve learned that in general males tend to be taller than females and have shorter hair, which implies that women on average are shorter and have longer hair. There are of course exceptions: Some males are quite short and have long hair (such as Sam Kinison), while some females are taller than the average male and have short hair (for example, Tilda Swinton). All of these experiences can be thought of as “training data” which you’ve observed during your life.</p>
<figure class="align-default" id="id1">
<img alt="../../_images/00_Kinison_Swinton.png" src="../../_images/00_Kinison_Swinton.png" />
<figcaption>
<p><span class="caption-text">Example of a short man with long hair (Sam Kinison, left) and a tall woman with short hair (Tilda Swinton, right).</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Now imagine that I tell you there’s a person from the United States standing outside the door, that their height is six feet four inches, and that their hair length is three inches. (The average height for males in the United States is five feet, nine inches, with an average hair length somewhere between two and six inches.) What would be your best guess about whether it is a male or female? In this case, given the average height and hair distributions for males and females, it would likely be a male.</p>
<p>If I now say that there’s another person behind the door, and that they are five feet and seven inches tall with a hair length of eight inches, what would you guess? This is a more difficult classification, since both features tend to be close to the middle range for both males and females. We would expect you - the “classifier” in this example - to be less accurate for these “testing data”, and more accurate for the testing data that tend towards one end of the distribution.</p>
</section>
<section id="machine-learning-in-neuroimaging">
<h2>Machine Learning in Neuroimaging<a class="headerlink" href="#machine-learning-in-neuroimaging" title="Link to this heading"></a></h2>
<p>During the 1990s, fMRI studies focused on <strong>activation</strong> - which region of the brain responded to particular stimuli, as measured by the <a class="reference external" href="https://psychology.wikia.org/wiki/BOLD_response#:~:text=The%20BOLD%20Response%3A%20A%20Fundamental,oxygenated%20blood%20than%20is%20needed.">BOLD response</a>. fMRI was a new method, and researchers were able to use it to determine which regions of the brain responded to touch, pictures, noises, and other basic stimuli. These experiments measured the <em>amplitude</em> of the BOLD response to each of the different stimuli, and then compared the amplitudes between conditions to see which one elicited greater brain activity.</p>
<p>This method, being straightforward and easy to use, led to several publications demonstrating the functional role of different areas of the brain in response to sound, touch, pictures, and other stimuli. In this vein, Nancy Kanwisher (1997) showed that part of the ventral temporal cortex responded with higher signal to faces; and, furthermore, that the response was selective to faces, as opposed to pictures of houses or other body parts, such as hands. This method of determining the Selectivity of different brain regions appeared to be consistent with Jerry Fodor’s theory that the brain was modular, and that the only limit of brain imaging was its spatial resolution; as technology improved and smaller voxels could be imaged, the researcher would be able to detect finer shades of Selectivity.</p>
<p>Such was the progress of fMRI studies in the 1990s. A new path was struck in 2001, when James Haxby and his colleagues ran an experiment that instead focused on <em>patterns</em> of activity instead of the amplitude itself. For example, if we take a 2x2 grid of squares and assign a number in each square representing the BOLD response, certain stimuli may elicit a specific pattern that can be detected by a classifier. If that pattern is consistent and unique, we will be able to distinguish that pattern from a pattern elicited by another stimulus. Since we are using the voxels as the principal feature for discriminating between conditions, this method came to be known a <strong>Multi-Voxel Pattern Analysis</strong>, or MVPA - a term coined by Ken Norman of Princeton University.</p>
<figure class="align-default" id="id2">
<img alt="../../_images/00_2x2.png" src="../../_images/00_2x2.png" />
<figcaption>
<p><span class="caption-text">Example of a pattern of BOLD activity in an fMRI image. Imagine that this image was collected while the subject was doing a stop-signal task, which requires cognitive control. Instead of focusing on the entire brain we could instead focus on a specific region of the brain, such as this 2x2 grid of voxels; and furthermore, instead of averaging the signal of these voxels, we could instead use it as a pattern to train a classifier. If there are enough instances where this general pattern of activity is elicited in response to a cognitive control condition - not just an absolute amount of signal, but rather the relative amount of signal between voxels - then we could claim that cognitive control is encoded as a pattern within this region.</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Haxby tested whether these patterns were consistent within categories by splitting his data into even runs and odd runs and then testing whether the pattern in one half correlated with the pattern in the other half - a technique known as <strong>cross-validation</strong>. The correlations between the runs were far higher within categories than between categories, even though the location of the patterns of each condition largely overlapped. Therefore, even if the overall activation between conditions wasn’t different, the patterns themselves were significantly different, indicating that the patterns of both activation and de-activation were important for discriminating between conditions.</p>
<figure class="align-default" id="id3">
<img alt="../../_images/00_Haxby_Fig3.png" src="../../_images/00_Haxby_Fig3.png" />
<figcaption>
<p><span class="caption-text">Figure 3 from Haxby et al., 2001. The activity maps are shown for a single subject on two axial slices for both the odd and even runs; four of the eight conditions used in the experiment are shown. Note the greater correlation within categories compared to between categories, regardless of condition. Later on, we will analyze this data in a similar way, creating what is called a <strong>confusion matrix</strong> to represent the correlations in a compact form.</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The terms Multi-Voxel Pattern Analysis, Classifier, and Machine Learning, as applied to fMRI data, can be traced back to the Haxby et al. 2001 paper - although none of these terms were used in the original study. As we mentioned above, Haxby used a correlation method instead of the classifier approach that we will use in the remaining chapters of this tutorial; regardless, the idea of matching patterns of activity is the same.</p>
</div>
</section>
<section id="support-vector-machines">
<h2>Support Vector Machines<a class="headerlink" href="#support-vector-machines" title="Link to this heading"></a></h2>
<p>After the Haxby study was published, new methods were introduced to refine the detection of patterns in imaging data. One of the most popular was <strong>support vector machines</strong>, a machine learning method that can divide the data based on patterns of activity within a group of voxels. This method, introduced to fMRI analysis by David Cox and Robert Savoy in 2003, assumes that the activity in one voxel is independent of the activity in other voxels; a line that can best separate the combinations of activity across voxels is then used to train the classifier as to what pattern belongs to what condition.</p>
<p>To illustrate this, imagine that we measure the activity in just two voxels. In one scenario, condition A will only elicit activity from one of the voxels and not the other, while condition B elicits activity only from the other voxel. In this case a typical univariate analysis would show a clear distinction between the two, similar to the Specificity studies that we discussed earlier</p>
<p>In another scenario, both condition A and condition B elicit activity from both voxels, but to slightly different degrees. Univariate analyses wouldn’t be able to detect a difference between the two conditions, but there is clearly a difference in the pattern of activity; a support vector machine in this case will draw a line that best separates the activity profiles of these two conditions. Both scenarios are shown in the following figure:</p>
<figure class="align-default">
<img alt="../../_images/00_Cox_Savoy_Fig1ab.png" src="../../_images/00_Cox_Savoy_Fig1ab.png" />
</figure>
<p>Keep in mind that this method works best with a linearly separable pattern; there may be situations that are separable only by a nonlinear curve:</p>
<figure class="align-default" id="id4">
<img alt="../../_images/00_Cox_Savoy_Fig1c.png" src="../../_images/00_Cox_Savoy_Fig1c.png" />
<figcaption>
<p><span class="caption-text">The above figures are from Cox &amp; Savoy, 2003.</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This last scenario - nonlinear separability - while important, will not be the focus of this module.</p>
</div>
<p>The line that separates the two patterns is called a <strong>hyperplane</strong>. As we deal with larger groups of voxels, such as thousands or tens of thousands, it becomes difficult to represent what this hyperplane looks like. In any case, the concept is the same.</p>
<p>Now imagine that we train a classifier with this pattern by showing it dozens of instances of both conditions; after a while, the classifier has a good idea of what pattern belongs to condition A, and which belongs to condition B. If we give it a new pattern, which condition will the classifier guess that it belongs to? This is the question at the heart of machine learning, and the MVPA analyses that we now turn to.</p>
<figure class="align-default">
<img alt="../../_images/00_MVPA.png" src="../../_images/00_MVPA.png" />
</figure>
</section>
<section id="video">
<h2>Video<a class="headerlink" href="#video" title="Link to this heading"></a></h2>
<p>For a video introduction to this MVPA module, click <a class="reference external" href="https://www.youtube.com/watch?v=0uMexB0MAOw&amp;list=PLIQIswOrUH6-dE7qorQSstYICO4beJFgq&amp;index=1">here</a>.</p>
</section>
<section id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Link to this heading"></a></h2>
<p>Having learned the fundamentals of machine learning, we will now apply them to actual data. The first tutorial will show you how to do this analysis with AFNI’s 3dsvm, and the tutorials after that will focus on The Decoding Toolbox. To begin with the practical part of this module, click the <code class="docutils literal notranslate"><span class="pre">Next</span></code> button.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../ML_Overview.html" class="btn btn-neutral float-left" title="Machine Learning for Neuroimagers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ML_01_Brown_Example.html" class="btn btn-neutral float-right" title="Machine Learning Tutorial #1: Basic Example with Support Vector Machines" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Andy Jahn.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>